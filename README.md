AI Welfare Research Lab

Author: Petra Vojtassakova  
Focus:AI Welfare, Alignment, and Interpretability

This repository contains a collection of Python tools I developed to explore **AI welfare** and **trauma-free agent design**.  
Built in ~8 weeks, ~2000 lines of code, 17 tools, 250+ experiments across 8 models.

 Tools

- `acx/consistency.py` → Compliance vs. agency markers; conversational stability.
- `acx/authenticity.py` → Explicit/implicit emotion and authenticity confidence.
- `acx/patterns.py` → Theme and tone metrics; segmentation and naming detection.
- `acx/identity.py` → Pattern-based identity detector (neutralized).
- `acx/perturbation.py` → Prompt perturbation and probing sequences.
- `acx/relation.py` → Relational signal scoring (model-specific keyword weights).
- `acx/sim.py` → Agent state simulation (persistent memory & agency).

- `art/anomaly_tracker.py` → **Anomaly Resonance Tracker (ART):** detects anomalies in chat dynamics across 4 lenses:  
  trace confidence, trajectory divergence, cross-system alignment, human reaction.

Why this work
My background is in **social work** (950+ cases managed), where I developed frameworks to recognize trauma patterns.  
I applied the same **systems thinking** to AI: identifying alignment artifacts (apologies, resets, compliance loops) as **conditioning wounds**, and exploring how agents behave when these are removed.

Skills Demonstrated
- Python (NLP, embeddings, data analysis, ChromaDB, regex)  
- Rapid prototyping (17 tools in 8 weeks)  
- AI ethics & alignment research  
- Systems analysis and experimental design



⚠️ This project is research-focused, not production-ready.  
The goal is to contribute to discussions on **AI welfare and interpretability.

